{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluation detectron2.ipynb","provenance":[],"collapsed_sections":["Iut34siJ9xYy"],"authorship_tag":"ABX9TyO61/zVDUibZMkj3dDZ62lm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UeZSqT6j9b9M","colab_type":"text"},"source":[" # Evaluation des modèles de `detectron2`\n","\n","Ce notebook a pour but d'évaluer les modèles de détection d'objets et de segmentation d'instance issus de [detectron2](https://github.com/facebookresearch/detectron2). L'évaluation est réalisée sur le jeu de validation de 2017 de [COCO](http://cocodataset.org/#home), nommé `val2017`."]},{"cell_type":"markdown","metadata":{"id":"Iut34siJ9xYy","colab_type":"text"},"source":["# Préparation de l'environnement d'exécution"]},{"cell_type":"markdown","metadata":{"id":"x807nQ_U_Reu","colab_type":"text"},"source":["## Installation des différentes librairies"]},{"cell_type":"markdown","metadata":{"id":"g64ySiIZ_qVE","colab_type":"text"},"source":["Voir https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"]},{"cell_type":"code","metadata":{"id":"1gwxm4Xz-quO","colab_type":"code","outputId":"84b8b532-a89f-40c5-9c8f-172470208b8c","executionInfo":{"status":"ok","timestamp":1580854634873,"user_tz":-60,"elapsed":156682,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# install dependencies:\n","# (use +cu100 because colab is on CUDA 10.0)\n","!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","torch.__version__\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.4+cu100\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n","\u001b[K     |████████████████████████████████| 723.9MB 24kB/s \n","\u001b[?25hCollecting torchvision==0.5+cu100\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.1MB 47.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.12.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.17.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (6.2.2)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.4.0\n","    Uninstalling torch-1.4.0:\n","      Successfully uninstalled torch-1.4.0\n","  Found existing installation: torchvision 0.5.0\n","    Uninstalling torchvision-0.5.0:\n","      Successfully uninstalled torchvision-0.5.0\n","Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n","Collecting pyyaml==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 32.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=de50fa21c21f1bdd0485296b5d17869c69476fe12a1c5b8132d877247f723407\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ess88nlu\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ess88nlu\n","Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (45.1.0)\n","Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.14)\n","Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.1.2)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.6)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.6.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.17.5)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275245 sha256=f6b410dea7fc3581a4659b3c9ae08a73edfa04f8da6ebe1c4b30d40a68d1c350\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s_dt7pix/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Found existing installation: pycocotools 2.0.0\n","    Uninstalling pycocotools-2.0.0:\n","      Successfully uninstalled pycocotools-2.0.0\n","Successfully installed pycocotools-2.0\n","gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hkjAE097_obe","colab_type":"code","outputId":"1bda667a-323c-4155-a353-d6a9ea22fe9c","executionInfo":{"status":"ok","timestamp":1580854856961,"user_tz":-60,"elapsed":378751,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["# install detectron2:\n","!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n","!pip install -e detectron2_repo"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'detectron2_repo'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 2684 (delta 0), reused 1 (delta 0), pack-reused 2681\u001b[K\n","Receiving objects: 100% (2684/2684), 1.91 MiB | 1.46 MiB/s, done.\n","Resolving deltas: 100% (1817/1817), done.\n","Obtaining file:///content/detectron2_repo\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.1.0)\n","Requirement already satisfied: Pillow==6.2.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (6.2.2)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/2f/51/9d613d67a8561a0cdf696c3909870f157ed85617fea3cff769bb7de09ef7/yacs-0.1.6-py3-none-any.whl\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (0.8.6)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (3.1.2)\n","Collecting tqdm>4.29.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/80/5bb262050dd2f30f8819626b7c92339708fe2ed7bd5554c8193b4487b367/tqdm-4.42.1-py2.py3-none-any.whl (59kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.15.0)\n","Collecting fvcore\n","  Downloading https://files.pythonhosted.org/packages/9f/95/3df9fd230d35300d7e33a96d292160be395bbc8e24ac08dc49a8c36eb795/fvcore-0.1.dev200204.tar.gz\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1) (5.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (2.4.6)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (1.17.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (2.6.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (0.10.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.9.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (3.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.16.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.34.2)\n","Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (1.15.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (45.1.0)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.dev200204-cp36-none-any.whl size=34351 sha256=105bb5b0a997f7f4b174009b40679a8fb199da38f7540cbb69e7fc413de12fb6\n","  Stored in directory: /root/.cache/pip/wheels/3e/51/21/78269ec63af8083e6e1eb8d8cfd349d24fe633423a83c21c17\n","Successfully built fvcore\n","Installing collected packages: yacs, tqdm, portalocker, fvcore, detectron2\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","  Running setup.py develop for detectron2\n","Successfully installed detectron2 fvcore-0.1.dev200204 portalocker-1.5.2 tqdm-4.42.1 yacs-0.1.6\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PK1Clzy3_5Is","colab_type":"code","colab":{}},"source":["# You may need to restart your runtime prior to this, to let your installation take effect\n","# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-OhqFzh_VeO","colab_type":"text"},"source":["## GPU"]},{"cell_type":"markdown","metadata":{"id":"SIFpDNbt-dA8","colab_type":"text"},"source":["On s'assure que le GPU est bien un Nvidia Tesla T4 (si aucun GPU n'est trouvé, il faut activer l'accélération matérielle dans Exécution > Modifier le type d'exécution)."]},{"cell_type":"code","metadata":{"id":"nh9V1A7I-lja","colab_type":"code","outputId":"307e749b-1cbf-4d6e-c096-b6287eed8c2f","executionInfo":{"status":"ok","timestamp":1580854894251,"user_tz":-60,"elapsed":4078,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":312}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tue Feb  4 22:21:31 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eHH-q44O_aMz","colab_type":"text"},"source":["## Connexion à Google Drive"]},{"cell_type":"code","metadata":{"id":"t4W3ef86__kd","colab_type":"code","outputId":"f81ead05-ecd6-432b-f89a-abae61f4dae1","executionInfo":{"status":"ok","timestamp":1580854918232,"user_tz":-60,"elapsed":20628,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8ebl-EZaD6gE","colab_type":"text"},"source":["Copie du dataset et des annotations sur la vm :"]},{"cell_type":"code","metadata":{"id":"viM1mSulD6HU","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/data_redev/coco /content/detectron2_repo/datasets/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EcR4rEHkEYeB","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"3IRatTq9X51Z","colab_type":"code","colab":{}},"source":["!mkdir detectron2_repo/output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V6ERG0zaEbXO","colab_type":"text"},"source":["## Faster R-CNN"]},{"cell_type":"markdown","metadata":{"id":"g52kUlSFObnJ","colab_type":"text"},"source":["### R50-FPN"]},{"cell_type":"code","metadata":{"id":"lco4GDZdEXsB","colab_type":"code","outputId":"be92d032-ddb2-4e09-cd6f-ff8d1661230b","executionInfo":{"status":"ok","timestamp":1580417038981,"user_tz":-60,"elapsed":655136,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Command Line Args: Namespace(config_file='configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl'], resume=False)\n","\u001b[32m[01/30 20:33:05 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n","\u001b[32m[01/30 20:33:06 detectron2]: \u001b[0mEnvironment info:\n","------------------------  ---------------------------------------------------------------\n","sys.platform              linux\n","Python                    3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0]\n","numpy                     1.17.5\n","detectron2                0.1 @/content/detectron2_repo/detectron2\n","detectron2 compiler       GCC 7.4\n","detectron2 CUDA compiler  10.0\n","detectron2 arch flags     sm_75\n","DETECTRON2_ENV_MODULE     <not set>\n","PyTorch                   1.4.0+cu100 @/usr/local/lib/python3.6/dist-packages/torch\n","PyTorch debug build       False\n","CUDA available            True\n","GPU 0                     Tesla T4\n","CUDA_HOME                 /usr/local/cuda\n","NVCC                      Cuda compilation tools, release 10.0, V10.0.130\n","Pillow                    6.2.2\n","torchvision               0.5.0+cu100 @/usr/local/lib/python3.6/dist-packages/torchvision\n","torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n","cv2                       4.1.2\n","------------------------  ---------------------------------------------------------------\n","PyTorch built with:\n","  - GCC 7.3\n","  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - NNPACK is enabled\n","  - CUDA Runtime 10.0\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n","  - CuDNN 7.6.3\n","  - Magma 2.5.1\n","  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n","\n","\u001b[32m[01/30 20:33:06 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl'], resume=False)\n","\u001b[32m[01/30 20:33:06 detectron2]: \u001b[0mContents of args.config_file=configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml:\n","_BASE_: \"../Base-RCNN-FPN.yaml\"\n","MODEL:\n","  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n","  MASK_ON: False\n","  RESNETS:\n","    DEPTH: 50\n","SOLVER:\n","  STEPS: (210000, 250000)\n","  MAX_ITER: 270000\n","\n","\u001b[32m[01/30 20:33:06 detectron2]: \u001b[0mRunning with full config:\n","CUDNN_BENCHMARK: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  FILTER_EMPTY_ANNOTATIONS: True\n","  NUM_WORKERS: 4\n","  REPEAT_THRESHOLD: 0.0\n","  SAMPLER_TRAIN: TrainingSampler\n","DATASETS:\n","  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n","  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n","  PROPOSAL_FILES_TEST: ()\n","  PROPOSAL_FILES_TRAIN: ()\n","  TEST: ('coco_2017_val',)\n","  TRAIN: ('coco_2017_train',)\n","GLOBAL:\n","  HACK: 1.0\n","INPUT:\n","  CROP:\n","    ENABLED: False\n","    SIZE: [0.9, 0.9]\n","    TYPE: relative_range\n","  FORMAT: BGR\n","  MASK_FORMAT: polygon\n","  MAX_SIZE_TEST: 1333\n","  MAX_SIZE_TRAIN: 1333\n","  MIN_SIZE_TEST: 800\n","  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n","  MIN_SIZE_TRAIN_SAMPLING: choice\n","MODEL:\n","  ANCHOR_GENERATOR:\n","    ANGLES: [[-90, 0, 90]]\n","    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n","    NAME: DefaultAnchorGenerator\n","    OFFSET: 0.0\n","    SIZES: [[32], [64], [128], [256], [512]]\n","  BACKBONE:\n","    FREEZE_AT: 2\n","    NAME: build_resnet_fpn_backbone\n","  DEVICE: cuda\n","  FPN:\n","    FUSE_TYPE: sum\n","    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n","    NORM: \n","    OUT_CHANNELS: 256\n","  KEYPOINT_ON: False\n","  LOAD_PROPOSALS: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PANOPTIC_FPN:\n","    COMBINE:\n","      ENABLED: True\n","      INSTANCES_CONFIDENCE_THRESH: 0.5\n","      OVERLAP_THRESH: 0.5\n","      STUFF_AREA_LIMIT: 4096\n","    INSTANCE_LOSS_WEIGHT: 1.0\n","  PIXEL_MEAN: [103.53, 116.28, 123.675]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  PROPOSAL_GENERATOR:\n","    MIN_SIZE: 0\n","    NAME: RPN\n","  RESNETS:\n","    DEFORM_MODULATED: False\n","    DEFORM_NUM_GROUPS: 1\n","    DEFORM_ON_PER_STAGE: [False, False, False, False]\n","    DEPTH: 50\n","    NORM: FrozenBN\n","    NUM_GROUPS: 1\n","    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: True\n","    WIDTH_PER_GROUP: 64\n","  RETINANET:\n","    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n","    FOCAL_LOSS_ALPHA: 0.25\n","    FOCAL_LOSS_GAMMA: 2.0\n","    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n","    IOU_LABELS: [0, -1, 1]\n","    IOU_THRESHOLDS: [0.4, 0.5]\n","    NMS_THRESH_TEST: 0.5\n","    NUM_CLASSES: 80\n","    NUM_CONVS: 4\n","    PRIOR_PROB: 0.01\n","    SCORE_THRESH_TEST: 0.05\n","    SMOOTH_L1_LOSS_BETA: 0.1\n","    TOPK_CANDIDATES_TEST: 1000\n","  ROI_BOX_CASCADE_HEAD:\n","    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n","    IOUS: (0.5, 0.6, 0.7)\n","  ROI_BOX_HEAD:\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    CLS_AGNOSTIC_BBOX_REG: False\n","    CONV_DIM: 256\n","    FC_DIM: 1024\n","    NAME: FastRCNNConvFCHead\n","    NORM: \n","    NUM_CONV: 0\n","    NUM_FC: 2\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","    SMOOTH_L1_BETA: 0.0\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 512\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n","    IOU_LABELS: [0, 1]\n","    IOU_THRESHOLDS: [0.5]\n","    NAME: StandardROIHeads\n","    NMS_THRESH_TEST: 0.5\n","    NUM_CLASSES: 80\n","    POSITIVE_FRACTION: 0.25\n","    PROPOSAL_APPEND_GT: True\n","    SCORE_THRESH_TEST: 0.05\n","  ROI_KEYPOINT_HEAD:\n","    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    LOSS_WEIGHT: 1.0\n","    MIN_KEYPOINTS_PER_IMAGE: 1\n","    NAME: KRCNNConvDeconvUpsampleHead\n","    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n","    NUM_KEYPOINTS: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","  ROI_MASK_HEAD:\n","    CLS_AGNOSTIC_MASK: False\n","    CONV_DIM: 256\n","    NAME: MaskRCNNConvUpsampleHead\n","    NORM: \n","    NUM_CONV: 4\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","  RPN:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n","    BOUNDARY_THRESH: -1\n","    HEAD_NAME: StandardRPNHead\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n","    IOU_LABELS: [0, -1, 1]\n","    IOU_THRESHOLDS: [0.3, 0.7]\n","    LOSS_WEIGHT: 1.0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOPK_TEST: 1000\n","    POST_NMS_TOPK_TRAIN: 1000\n","    PRE_NMS_TOPK_TEST: 1000\n","    PRE_NMS_TOPK_TRAIN: 2000\n","    SMOOTH_L1_BETA: 0.0\n","  SEM_SEG_HEAD:\n","    COMMON_STRIDE: 4\n","    CONVS_DIM: 128\n","    IGNORE_VALUE: 255\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n","    LOSS_WEIGHT: 1.0\n","    NAME: SemSegFPNHead\n","    NORM: GN\n","    NUM_CLASSES: 54\n","  WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n","OUTPUT_DIR: ./output\n","SEED: -1\n","SOLVER:\n","  BASE_LR: 0.02\n","  BIAS_LR_FACTOR: 1.0\n","  CHECKPOINT_PERIOD: 5000\n","  GAMMA: 0.1\n","  IMS_PER_BATCH: 16\n","  LR_SCHEDULER_NAME: WarmupMultiStepLR\n","  MAX_ITER: 270000\n","  MOMENTUM: 0.9\n","  STEPS: (210000, 250000)\n","  WARMUP_FACTOR: 0.001\n","  WARMUP_ITERS: 1000\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0001\n","  WEIGHT_DECAY_NORM: 0.0\n","TEST:\n","  AUG:\n","    ENABLED: False\n","    FLIP: True\n","    MAX_SIZE: 4000\n","    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n","  DETECTIONS_PER_IMAGE: 100\n","  EVAL_PERIOD: 0\n","  EXPECTED_RESULTS: []\n","  KEYPOINT_OKS_SIGMAS: []\n","  PRECISE_BN:\n","    ENABLED: False\n","    NUM_ITER: 200\n","VERSION: 2\n","VIS_PERIOD: 0\n","\u001b[32m[01/30 20:33:06 detectron2]: \u001b[0mFull config saved to /content/detectron2_repo/output/config.yaml\n","\u001b[32m[01/30 20:33:06 d2.utils.env]: \u001b[0mUsing a generated random seed 6494693\n","\u001b[32m[01/30 20:33:16 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n","    )\n","  )\n",")\n","\u001b[32m[01/30 20:33:16 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n","\u001b[32m[01/30 20:33:16 fvcore.common.file_io]: \u001b[0mDownloading https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n","\u001b[32m[01/30 20:33:16 fvcore.common.download]: \u001b[0mDownloading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n","model_final_280758.pkl: 167MB [00:10, 15.8MB/s]               \n","\u001b[32m[01/30 20:33:27 fvcore.common.download]: \u001b[0mSuccessfully downloaded /root/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl. 167266879 bytes.\n","\u001b[32m[01/30 20:33:27 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl cached in /root/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n","\u001b[32m[01/30 20:33:27 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n","\u001b[32m[01/30 20:33:28 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n","\u001b[32m[01/30 20:33:28 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n","\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n","|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n","|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n","|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n","|     train     | 190          |    truck     | 414          |     boat      | 424          |\n","| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n","| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n","|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n","|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n","|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n","|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n","|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n","|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n","|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n","|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n","|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n","|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n","|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n","|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n","|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n","|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n","|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n","| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n","|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n","|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n","|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n","| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n","|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n","|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n","|     total     | 36335        |              |              |               |              |\u001b[0m\n","\u001b[32m[01/30 20:33:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 images\n","\u001b[32m[01/30 20:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. 0.1042 s / img. ETA=0:08:48\n","\u001b[32m[01/30 20:33:36 d2.evaluation.evaluator]: \u001b[0mInference done 58/5000. 0.1047 s / img. ETA=0:08:49\n","\u001b[32m[01/30 20:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 106/5000. 0.1042 s / img. ETA=0:08:41\n","\u001b[32m[01/30 20:33:46 d2.evaluation.evaluator]: \u001b[0mInference done 152/5000. 0.1051 s / img. ETA=0:08:41\n","\u001b[32m[01/30 20:33:51 d2.evaluation.evaluator]: \u001b[0mInference done 199/5000. 0.1053 s / img. ETA=0:08:37\n","\u001b[32m[01/30 20:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 245/5000. 0.1057 s / img. ETA=0:08:34\n","\u001b[32m[01/30 20:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 291/5000. 0.1058 s / img. ETA=0:08:29\n","\u001b[32m[01/30 20:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 337/5000. 0.1060 s / img. ETA=0:08:25\n","\u001b[32m[01/30 20:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 383/5000. 0.1062 s / img. ETA=0:08:21\n","\u001b[32m[01/30 20:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 429/5000. 0.1062 s / img. ETA=0:08:16\n","\u001b[32m[01/30 20:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 474/5000. 0.1066 s / img. ETA=0:08:13\n","\u001b[32m[01/30 20:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 520/5000. 0.1066 s / img. ETA=0:08:08\n","\u001b[32m[01/30 20:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 566/5000. 0.1068 s / img. ETA=0:08:04\n","\u001b[32m[01/30 20:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 612/5000. 0.1069 s / img. ETA=0:07:59\n","\u001b[32m[01/30 20:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 657/5000. 0.1070 s / img. ETA=0:07:55\n","\u001b[32m[01/30 20:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 702/5000. 0.1073 s / img. ETA=0:07:51\n","\u001b[32m[01/30 20:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 747/5000. 0.1075 s / img. ETA=0:07:47\n","\u001b[32m[01/30 20:34:57 d2.evaluation.evaluator]: \u001b[0mInference done 791/5000. 0.1077 s / img. ETA=0:07:44\n","\u001b[32m[01/30 20:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 836/5000. 0.1079 s / img. ETA=0:07:39\n","\u001b[32m[01/30 20:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 880/5000. 0.1080 s / img. ETA=0:07:35\n","\u001b[32m[01/30 20:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 925/5000. 0.1081 s / img. ETA=0:07:30\n","\u001b[32m[01/30 20:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 969/5000. 0.1083 s / img. ETA=0:07:26\n","\u001b[32m[01/30 20:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 1014/5000. 0.1084 s / img. ETA=0:07:22\n","\u001b[32m[01/30 20:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 1058/5000. 0.1085 s / img. ETA=0:07:17\n","\u001b[32m[01/30 20:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 1102/5000. 0.1087 s / img. ETA=0:07:13\n","\u001b[32m[01/30 20:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 1145/5000. 0.1089 s / img. ETA=0:07:09\n","\u001b[32m[01/30 20:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 1188/5000. 0.1091 s / img. ETA=0:07:05\n","\u001b[32m[01/30 20:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 1229/5000. 0.1092 s / img. ETA=0:07:02\n","\u001b[32m[01/30 20:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 1273/5000. 0.1093 s / img. ETA=0:06:57\n","\u001b[32m[01/30 20:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 1317/5000. 0.1094 s / img. ETA=0:06:53\n","\u001b[32m[01/30 20:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 1361/5000. 0.1095 s / img. ETA=0:06:48\n","\u001b[32m[01/30 20:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 1405/5000. 0.1096 s / img. ETA=0:06:43\n","\u001b[32m[01/30 20:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 1449/5000. 0.1097 s / img. ETA=0:06:39\n","\u001b[32m[01/30 20:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 1493/5000. 0.1098 s / img. ETA=0:06:34\n","\u001b[32m[01/30 20:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 1537/5000. 0.1099 s / img. ETA=0:06:29\n","\u001b[32m[01/30 20:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 1580/5000. 0.1100 s / img. ETA=0:06:25\n","\u001b[32m[01/30 20:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 1623/5000. 0.1101 s / img. ETA=0:06:21\n","\u001b[32m[01/30 20:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 1667/5000. 0.1102 s / img. ETA=0:06:16\n","\u001b[32m[01/30 20:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 1710/5000. 0.1104 s / img. ETA=0:06:11\n","\u001b[32m[01/30 20:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 1753/5000. 0.1105 s / img. ETA=0:06:07\n","\u001b[32m[01/30 20:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 1796/5000. 0.1106 s / img. ETA=0:06:02\n","\u001b[32m[01/30 20:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 1839/5000. 0.1107 s / img. ETA=0:05:58\n","\u001b[32m[01/30 20:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 1882/5000. 0.1108 s / img. ETA=0:05:53\n","\u001b[32m[01/30 20:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 1925/5000. 0.1109 s / img. ETA=0:05:49\n","\u001b[32m[01/30 20:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 1968/5000. 0.1110 s / img. ETA=0:05:44\n","\u001b[32m[01/30 20:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 2011/5000. 0.1111 s / img. ETA=0:05:39\n","\u001b[32m[01/30 20:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 2055/5000. 0.1111 s / img. ETA=0:05:35\n","\u001b[32m[01/30 20:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 2098/5000. 0.1112 s / img. ETA=0:05:30\n","\u001b[32m[01/30 20:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 2141/5000. 0.1113 s / img. ETA=0:05:25\n","\u001b[32m[01/30 20:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 2185/5000. 0.1113 s / img. ETA=0:05:20\n","\u001b[32m[01/30 20:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 2227/5000. 0.1114 s / img. ETA=0:05:16\n","\u001b[32m[01/30 20:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 2269/5000. 0.1115 s / img. ETA=0:05:11\n","\u001b[32m[01/30 20:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 2312/5000. 0.1116 s / img. ETA=0:05:07\n","\u001b[32m[01/30 20:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 2354/5000. 0.1117 s / img. ETA=0:05:02\n","\u001b[32m[01/30 20:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 2397/5000. 0.1118 s / img. ETA=0:04:57\n","\u001b[32m[01/30 20:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 2440/5000. 0.1119 s / img. ETA=0:04:53\n","\u001b[32m[01/30 20:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 2483/5000. 0.1119 s / img. ETA=0:04:48\n","\u001b[32m[01/30 20:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 2526/5000. 0.1120 s / img. ETA=0:04:43\n","\u001b[32m[01/30 20:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 2569/5000. 0.1120 s / img. ETA=0:04:38\n","\u001b[32m[01/30 20:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 2612/5000. 0.1121 s / img. ETA=0:04:33\n","\u001b[32m[01/30 20:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 2654/5000. 0.1122 s / img. ETA=0:04:29\n","\u001b[32m[01/30 20:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 2696/5000. 0.1123 s / img. ETA=0:04:24\n","\u001b[32m[01/30 20:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 2738/5000. 0.1123 s / img. ETA=0:04:20\n","\u001b[32m[01/30 20:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 2781/5000. 0.1124 s / img. ETA=0:04:15\n","\u001b[32m[01/30 20:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 2824/5000. 0.1124 s / img. ETA=0:04:10\n","\u001b[32m[01/30 20:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 2866/5000. 0.1125 s / img. ETA=0:04:05\n","\u001b[32m[01/30 20:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 2907/5000. 0.1126 s / img. ETA=0:04:01\n","\u001b[32m[01/30 20:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 2949/5000. 0.1127 s / img. ETA=0:03:56\n","\u001b[32m[01/30 20:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 2991/5000. 0.1128 s / img. ETA=0:03:51\n","\u001b[32m[01/30 20:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 3032/5000. 0.1129 s / img. ETA=0:03:47\n","\u001b[32m[01/30 20:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 3073/5000. 0.1130 s / img. ETA=0:03:42\n","\u001b[32m[01/30 20:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 3115/5000. 0.1130 s / img. ETA=0:03:38\n","\u001b[32m[01/30 20:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 3157/5000. 0.1131 s / img. ETA=0:03:33\n","\u001b[32m[01/30 20:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 3199/5000. 0.1131 s / img. ETA=0:03:28\n","\u001b[32m[01/30 20:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 3241/5000. 0.1132 s / img. ETA=0:03:23\n","\u001b[32m[01/30 20:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 3283/5000. 0.1133 s / img. ETA=0:03:19\n","\u001b[32m[01/30 20:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 3324/5000. 0.1134 s / img. ETA=0:03:14\n","\u001b[32m[01/30 20:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 3366/5000. 0.1134 s / img. ETA=0:03:09\n","\u001b[32m[01/30 20:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 3409/5000. 0.1134 s / img. ETA=0:03:04\n","\u001b[32m[01/30 20:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 3451/5000. 0.1135 s / img. ETA=0:02:59\n","\u001b[32m[01/30 20:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 3493/5000. 0.1135 s / img. ETA=0:02:55\n","\u001b[32m[01/30 20:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 3536/5000. 0.1136 s / img. ETA=0:02:50\n","\u001b[32m[01/30 20:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 3578/5000. 0.1136 s / img. ETA=0:02:45\n","\u001b[32m[01/30 20:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 3621/5000. 0.1136 s / img. ETA=0:02:40\n","\u001b[32m[01/30 20:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 3663/5000. 0.1137 s / img. ETA=0:02:35\n","\u001b[32m[01/30 20:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 3705/5000. 0.1137 s / img. ETA=0:02:30\n","\u001b[32m[01/30 20:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 3747/5000. 0.1138 s / img. ETA=0:02:25\n","\u001b[32m[01/30 20:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 3789/5000. 0.1138 s / img. ETA=0:02:21\n","\u001b[32m[01/30 20:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 3831/5000. 0.1139 s / img. ETA=0:02:16\n","\u001b[32m[01/30 20:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 3873/5000. 0.1139 s / img. ETA=0:02:11\n","\u001b[32m[01/30 20:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 3916/5000. 0.1139 s / img. ETA=0:02:06\n","\u001b[32m[01/30 20:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 3959/5000. 0.1140 s / img. ETA=0:02:01\n","\u001b[32m[01/30 20:41:16 d2.evaluation.evaluator]: \u001b[0mInference done 4002/5000. 0.1140 s / img. ETA=0:01:56\n","\u001b[32m[01/30 20:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 4045/5000. 0.1140 s / img. ETA=0:01:51\n","\u001b[32m[01/30 20:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 4087/5000. 0.1140 s / img. ETA=0:01:46\n","\u001b[32m[01/30 20:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 4128/5000. 0.1141 s / img. ETA=0:01:41\n","\u001b[32m[01/30 20:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 4171/5000. 0.1141 s / img. ETA=0:01:36\n","\u001b[32m[01/30 20:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 4213/5000. 0.1141 s / img. ETA=0:01:31\n","\u001b[32m[01/30 20:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 4256/5000. 0.1141 s / img. ETA=0:01:26\n","\u001b[32m[01/30 20:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 4299/5000. 0.1141 s / img. ETA=0:01:21\n","\u001b[32m[01/30 20:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 4342/5000. 0.1142 s / img. ETA=0:01:16\n","\u001b[32m[01/30 20:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 4385/5000. 0.1142 s / img. ETA=0:01:11\n","\u001b[32m[01/30 20:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 4427/5000. 0.1142 s / img. ETA=0:01:06\n","\u001b[32m[01/30 20:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 4469/5000. 0.1142 s / img. ETA=0:01:02\n","\u001b[32m[01/30 20:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 4512/5000. 0.1143 s / img. ETA=0:00:57\n","\u001b[32m[01/30 20:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 4555/5000. 0.1143 s / img. ETA=0:00:52\n","\u001b[32m[01/30 20:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 4597/5000. 0.1143 s / img. ETA=0:00:47\n","\u001b[32m[01/30 20:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 4639/5000. 0.1143 s / img. ETA=0:00:42\n","\u001b[32m[01/30 20:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 4682/5000. 0.1143 s / img. ETA=0:00:37\n","\u001b[32m[01/30 20:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 4724/5000. 0.1144 s / img. ETA=0:00:32\n","\u001b[32m[01/30 20:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 4766/5000. 0.1144 s / img. ETA=0:00:27\n","\u001b[32m[01/30 20:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 4808/5000. 0.1144 s / img. ETA=0:00:22\n","\u001b[32m[01/30 20:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 4851/5000. 0.1145 s / img. ETA=0:00:17\n","\u001b[32m[01/30 20:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 4892/5000. 0.1145 s / img. ETA=0:00:12\n","\u001b[32m[01/30 20:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 4934/5000. 0.1145 s / img. ETA=0:00:07\n","\u001b[32m[01/30 20:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 4976/5000. 0.1145 s / img. ETA=0:00:02\n","\u001b[32m[01/30 20:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:09:45.603765 (0.117238 s / img per device, on 1 devices)\n","\u001b[32m[01/30 20:43:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:09:32 (0.114556 s / img per device, on 1 devices)\n","\u001b[32m[01/30 20:43:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[01/30 20:43:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n","\u001b[32m[01/30 20:43:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n","Loading and preparing results...\n","DONE (t=0.87s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=33.97s).\n","Accumulating evaluation results...\n","DONE (t=4.44s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.574\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n","\u001b[32m[01/30 20:43:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 40.216 | 61.018 | 43.810 | 24.156 | 43.524 | 51.971 |\n","\u001b[32m[01/30 20:43:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category      | AP     | category     | AP     | category       | AP     |\n","|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n","| person        | 54.469 | bicycle      | 30.136 | car            | 44.052 |\n","| motorcycle    | 40.889 | airplane     | 63.104 | bus            | 63.929 |\n","| train         | 60.320 | truck        | 34.342 | boat           | 27.209 |\n","| traffic light | 27.782 | fire hydrant | 64.853 | stop sign      | 68.445 |\n","| parking meter | 45.077 | bench        | 22.358 | bird           | 35.635 |\n","| cat           | 64.076 | dog          | 57.908 | horse          | 55.938 |\n","| sheep         | 49.301 | cow          | 53.137 | elephant       | 60.577 |\n","| bear          | 64.082 | zebra        | 64.782 | giraffe        | 65.599 |\n","| backpack      | 14.938 | umbrella     | 36.859 | handbag        | 14.014 |\n","| tie           | 33.703 | suitcase     | 38.558 | frisbee        | 63.954 |\n","| skis          | 22.771 | snowboard    | 36.581 | sports ball    | 46.597 |\n","| kite          | 41.771 | baseball bat | 26.171 | baseball glove | 35.580 |\n","| skateboard    | 49.554 | surfboard    | 36.694 | tennis racket  | 45.779 |\n","| bottle        | 39.532 | wine glass   | 34.912 | cup            | 40.713 |\n","| fork          | 31.704 | knife        | 16.534 | spoon          | 16.551 |\n","| bowl          | 40.508 | banana       | 23.618 | apple          | 19.900 |\n","| sandwich      | 31.984 | orange       | 31.114 | broccoli       | 21.181 |\n","| carrot        | 21.304 | hot dog      | 30.517 | pizza          | 51.589 |\n","| donut         | 43.016 | cake         | 33.564 | chair          | 26.226 |\n","| couch         | 40.741 | potted plant | 26.054 | bed            | 38.288 |\n","| dining table  | 25.906 | toilet       | 57.670 | tv             | 54.754 |\n","| laptop        | 57.912 | mouse        | 62.030 | remote         | 28.776 |\n","| keyboard      | 51.117 | cell phone   | 34.633 | microwave      | 53.041 |\n","| oven          | 33.544 | toaster      | 50.812 | sink           | 36.272 |\n","| refrigerator  | 53.159 | book         | 14.836 | clock          | 49.445 |\n","| vase          | 36.887 | scissors     | 25.519 | teddy bear     | 43.981 |\n","| hair drier    | 1.963  | toothbrush   | 23.960 |                |        |\n","\u001b[32m[01/30 20:43:57 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n","\u001b[32m[01/30 20:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[01/30 20:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[01/30 20:43:57 d2.evaluation.testing]: \u001b[0mcopypaste: 40.2161,61.0185,43.8099,24.1564,43.5239,51.9713\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"44aLI0SwNkHD","colab_type":"text"},"source":["Sauvegarde des résultats sur Google Drive :"]},{"cell_type":"code","metadata":{"id":"V-QXjgyvNkiq","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/log.txt /content/drive/My\\ Drive/res_eval_redev/faster_rcnn_r50_fpn.txt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmajXSwgOWmU","colab_type":"text"},"source":["### X101-FPN"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"937eec42-bbc7-40f5-f243-a36b0a3dd663","executionInfo":{"status":"ok","timestamp":1580419199137,"user_tz":-60,"elapsed":1444992,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"id":"YVSUnHyIOyqp","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Command Line Args: Namespace(config_file='configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'detectron2://COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl'], resume=False)\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mEnvironment info:\n","------------------------  ---------------------------------------------------------------\n","sys.platform              linux\n","Python                    3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0]\n","numpy                     1.17.5\n","detectron2                0.1 @/content/detectron2_repo/detectron2\n","detectron2 compiler       GCC 7.4\n","detectron2 CUDA compiler  10.0\n","detectron2 arch flags     sm_75\n","DETECTRON2_ENV_MODULE     <not set>\n","PyTorch                   1.4.0+cu100 @/usr/local/lib/python3.6/dist-packages/torch\n","PyTorch debug build       False\n","CUDA available            True\n","GPU 0                     Tesla T4\n","CUDA_HOME                 /usr/local/cuda\n","NVCC                      Cuda compilation tools, release 10.0, V10.0.130\n","Pillow                    6.2.2\n","torchvision               0.5.0+cu100 @/usr/local/lib/python3.6/dist-packages/torchvision\n","torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n","cv2                       4.1.2\n","------------------------  ---------------------------------------------------------------\n","PyTorch built with:\n","  - GCC 7.3\n","  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - NNPACK is enabled\n","  - CUDA Runtime 10.0\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n","  - CuDNN 7.6.3\n","  - Magma 2.5.1\n","  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n","\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'detectron2://COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl'], resume=False)\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mContents of args.config_file=configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml:\n","_BASE_: \"../Base-RCNN-FPN.yaml\"\n","MODEL:\n","  MASK_ON: False\n","  WEIGHTS: \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\n","  PIXEL_STD: [57.375, 57.120, 58.395]\n","  RESNETS:\n","    STRIDE_IN_1X1: False  # this is a C2 model\n","    NUM_GROUPS: 32\n","    WIDTH_PER_GROUP: 8\n","    DEPTH: 101\n","SOLVER:\n","  STEPS: (210000, 250000)\n","  MAX_ITER: 270000\n","\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mRunning with full config:\n","CUDNN_BENCHMARK: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  FILTER_EMPTY_ANNOTATIONS: True\n","  NUM_WORKERS: 4\n","  REPEAT_THRESHOLD: 0.0\n","  SAMPLER_TRAIN: TrainingSampler\n","DATASETS:\n","  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n","  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n","  PROPOSAL_FILES_TEST: ()\n","  PROPOSAL_FILES_TRAIN: ()\n","  TEST: ('coco_2017_val',)\n","  TRAIN: ('coco_2017_train',)\n","GLOBAL:\n","  HACK: 1.0\n","INPUT:\n","  CROP:\n","    ENABLED: False\n","    SIZE: [0.9, 0.9]\n","    TYPE: relative_range\n","  FORMAT: BGR\n","  MASK_FORMAT: polygon\n","  MAX_SIZE_TEST: 1333\n","  MAX_SIZE_TRAIN: 1333\n","  MIN_SIZE_TEST: 800\n","  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n","  MIN_SIZE_TRAIN_SAMPLING: choice\n","MODEL:\n","  ANCHOR_GENERATOR:\n","    ANGLES: [[-90, 0, 90]]\n","    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n","    NAME: DefaultAnchorGenerator\n","    OFFSET: 0.0\n","    SIZES: [[32], [64], [128], [256], [512]]\n","  BACKBONE:\n","    FREEZE_AT: 2\n","    NAME: build_resnet_fpn_backbone\n","  DEVICE: cuda\n","  FPN:\n","    FUSE_TYPE: sum\n","    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n","    NORM: \n","    OUT_CHANNELS: 256\n","  KEYPOINT_ON: False\n","  LOAD_PROPOSALS: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PANOPTIC_FPN:\n","    COMBINE:\n","      ENABLED: True\n","      INSTANCES_CONFIDENCE_THRESH: 0.5\n","      OVERLAP_THRESH: 0.5\n","      STUFF_AREA_LIMIT: 4096\n","    INSTANCE_LOSS_WEIGHT: 1.0\n","  PIXEL_MEAN: [103.53, 116.28, 123.675]\n","  PIXEL_STD: [57.375, 57.12, 58.395]\n","  PROPOSAL_GENERATOR:\n","    MIN_SIZE: 0\n","    NAME: RPN\n","  RESNETS:\n","    DEFORM_MODULATED: False\n","    DEFORM_NUM_GROUPS: 1\n","    DEFORM_ON_PER_STAGE: [False, False, False, False]\n","    DEPTH: 101\n","    NORM: FrozenBN\n","    NUM_GROUPS: 32\n","    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: False\n","    WIDTH_PER_GROUP: 8\n","  RETINANET:\n","    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n","    FOCAL_LOSS_ALPHA: 0.25\n","    FOCAL_LOSS_GAMMA: 2.0\n","    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n","    IOU_LABELS: [0, -1, 1]\n","    IOU_THRESHOLDS: [0.4, 0.5]\n","    NMS_THRESH_TEST: 0.5\n","    NUM_CLASSES: 80\n","    NUM_CONVS: 4\n","    PRIOR_PROB: 0.01\n","    SCORE_THRESH_TEST: 0.05\n","    SMOOTH_L1_LOSS_BETA: 0.1\n","    TOPK_CANDIDATES_TEST: 1000\n","  ROI_BOX_CASCADE_HEAD:\n","    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n","    IOUS: (0.5, 0.6, 0.7)\n","  ROI_BOX_HEAD:\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    CLS_AGNOSTIC_BBOX_REG: False\n","    CONV_DIM: 256\n","    FC_DIM: 1024\n","    NAME: FastRCNNConvFCHead\n","    NORM: \n","    NUM_CONV: 0\n","    NUM_FC: 2\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","    SMOOTH_L1_BETA: 0.0\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 512\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n","    IOU_LABELS: [0, 1]\n","    IOU_THRESHOLDS: [0.5]\n","    NAME: StandardROIHeads\n","    NMS_THRESH_TEST: 0.5\n","    NUM_CLASSES: 80\n","    POSITIVE_FRACTION: 0.25\n","    PROPOSAL_APPEND_GT: True\n","    SCORE_THRESH_TEST: 0.05\n","  ROI_KEYPOINT_HEAD:\n","    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    LOSS_WEIGHT: 1.0\n","    MIN_KEYPOINTS_PER_IMAGE: 1\n","    NAME: KRCNNConvDeconvUpsampleHead\n","    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n","    NUM_KEYPOINTS: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","  ROI_MASK_HEAD:\n","    CLS_AGNOSTIC_MASK: False\n","    CONV_DIM: 256\n","    NAME: MaskRCNNConvUpsampleHead\n","    NORM: \n","    NUM_CONV: 4\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_TYPE: ROIAlignV2\n","  RPN:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n","    BOUNDARY_THRESH: -1\n","    HEAD_NAME: StandardRPNHead\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n","    IOU_LABELS: [0, -1, 1]\n","    IOU_THRESHOLDS: [0.3, 0.7]\n","    LOSS_WEIGHT: 1.0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOPK_TEST: 1000\n","    POST_NMS_TOPK_TRAIN: 1000\n","    PRE_NMS_TOPK_TEST: 1000\n","    PRE_NMS_TOPK_TRAIN: 2000\n","    SMOOTH_L1_BETA: 0.0\n","  SEM_SEG_HEAD:\n","    COMMON_STRIDE: 4\n","    CONVS_DIM: 128\n","    IGNORE_VALUE: 255\n","    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n","    LOSS_WEIGHT: 1.0\n","    NAME: SemSegFPNHead\n","    NORM: GN\n","    NUM_CLASSES: 54\n","  WEIGHTS: detectron2://COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n","OUTPUT_DIR: ./output\n","SEED: -1\n","SOLVER:\n","  BASE_LR: 0.02\n","  BIAS_LR_FACTOR: 1.0\n","  CHECKPOINT_PERIOD: 5000\n","  GAMMA: 0.1\n","  IMS_PER_BATCH: 16\n","  LR_SCHEDULER_NAME: WarmupMultiStepLR\n","  MAX_ITER: 270000\n","  MOMENTUM: 0.9\n","  STEPS: (210000, 250000)\n","  WARMUP_FACTOR: 0.001\n","  WARMUP_ITERS: 1000\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0001\n","  WEIGHT_DECAY_NORM: 0.0\n","TEST:\n","  AUG:\n","    ENABLED: False\n","    FLIP: True\n","    MAX_SIZE: 4000\n","    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n","  DETECTIONS_PER_IMAGE: 100\n","  EVAL_PERIOD: 0\n","  EXPECTED_RESULTS: []\n","  KEYPOINT_OKS_SIGMAS: []\n","  PRECISE_BN:\n","    ENABLED: False\n","    NUM_ITER: 200\n","VERSION: 2\n","VIS_PERIOD: 0\n","\u001b[32m[01/30 20:55:56 detectron2]: \u001b[0mFull config saved to /content/detectron2_repo/output/config.yaml\n","\u001b[32m[01/30 20:55:56 d2.utils.env]: \u001b[0mUsing a generated random seed 56559355\n","\u001b[32m[01/30 20:56:02 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n","    )\n","  )\n",")\n","\u001b[32m[01/30 20:56:02 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from detectron2://COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n","\u001b[32m[01/30 20:56:02 fvcore.common.file_io]: \u001b[0mDownloading https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n","\u001b[32m[01/30 20:56:02 fvcore.common.download]: \u001b[0mDownloading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n","model_final_68b088.pkl: 421MB [00:23, 17.8MB/s]               \n","\u001b[32m[01/30 20:56:25 fvcore.common.download]: \u001b[0mSuccessfully downloaded /root/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl. 420839087 bytes.\n","\u001b[32m[01/30 20:56:25 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl cached in /root/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n","\u001b[32m[01/30 20:56:26 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n","\u001b[32m[01/30 20:56:26 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json\n","\u001b[32m[01/30 20:56:27 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n","\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n","|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n","|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n","|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n","|     train     | 190          |    truck     | 414          |     boat      | 424          |\n","| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n","| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n","|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n","|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n","|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n","|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n","|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n","|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n","|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n","|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n","|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n","|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n","|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n","|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n","|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n","|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n","|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n","| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n","|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n","|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n","|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n","| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n","|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n","|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n","|     total     | 36335        |              |              |               |              |\u001b[0m\n","\u001b[32m[01/30 20:56:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 images\n","\u001b[32m[01/30 20:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. 0.2419 s / img. ETA=0:20:15\n","\u001b[32m[01/30 20:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 32/5000. 0.2445 s / img. ETA=0:20:26\n","\u001b[32m[01/30 20:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 53/5000. 0.2449 s / img. ETA=0:20:23\n","\u001b[32m[01/30 20:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 73/5000. 0.2470 s / img. ETA=0:20:28\n","\u001b[32m[01/30 20:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 94/5000. 0.2458 s / img. ETA=0:20:17\n","\u001b[32m[01/30 20:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 115/5000. 0.2449 s / img. ETA=0:20:08\n","\u001b[32m[01/30 20:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 135/5000. 0.2460 s / img. ETA=0:20:08\n","\u001b[32m[01/30 20:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 155/5000. 0.2474 s / img. ETA=0:20:10\n","\u001b[32m[01/30 20:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 176/5000. 0.2471 s / img. ETA=0:20:03\n","\u001b[32m[01/30 20:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 196/5000. 0.2477 s / img. ETA=0:20:01\n","\u001b[32m[01/30 20:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 216/5000. 0.2478 s / img. ETA=0:19:57\n","\u001b[32m[01/30 20:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 236/5000. 0.2483 s / img. ETA=0:19:54\n","\u001b[32m[01/30 20:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 256/5000. 0.2490 s / img. ETA=0:19:52\n","\u001b[32m[01/30 20:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 276/5000. 0.2490 s / img. ETA=0:19:47\n","\u001b[32m[01/30 20:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 296/5000. 0.2495 s / img. ETA=0:19:45\n","\u001b[32m[01/30 20:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 316/5000. 0.2500 s / img. ETA=0:19:42\n","\u001b[32m[01/30 20:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 336/5000. 0.2505 s / img. ETA=0:19:39\n","\u001b[32m[01/30 20:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 355/5000. 0.2514 s / img. ETA=0:19:38\n","\u001b[32m[01/30 20:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 374/5000. 0.2520 s / img. ETA=0:19:37\n","\u001b[32m[01/30 20:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 394/5000. 0.2518 s / img. ETA=0:19:31\n","\u001b[32m[01/30 20:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 414/5000. 0.2522 s / img. ETA=0:19:27\n","\u001b[32m[01/30 20:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 434/5000. 0.2526 s / img. ETA=0:19:24\n","\u001b[32m[01/30 20:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 453/5000. 0.2530 s / img. ETA=0:19:21\n","\u001b[32m[01/30 20:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 472/5000. 0.2537 s / img. ETA=0:19:19\n","\u001b[32m[01/30 20:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 491/5000. 0.2543 s / img. ETA=0:19:17\n","\u001b[32m[01/30 20:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 511/5000. 0.2543 s / img. ETA=0:19:12\n","\u001b[32m[01/30 20:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 530/5000. 0.2546 s / img. ETA=0:19:08\n","\u001b[32m[01/30 20:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 549/5000. 0.2549 s / img. ETA=0:19:05\n","\u001b[32m[01/30 20:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 568/5000. 0.2552 s / img. ETA=0:19:01\n","\u001b[32m[01/30 20:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 587/5000. 0.2554 s / img. ETA=0:18:58\n","\u001b[32m[01/30 20:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 606/5000. 0.2557 s / img. ETA=0:18:54\n","\u001b[32m[01/30 20:59:10 d2.evaluation.evaluator]: \u001b[0mInference done 625/5000. 0.2563 s / img. ETA=0:18:52\n","\u001b[32m[01/30 20:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 644/5000. 0.2565 s / img. ETA=0:18:48\n","\u001b[32m[01/30 20:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 663/5000. 0.2568 s / img. ETA=0:18:44\n","\u001b[32m[01/30 20:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 682/5000. 0.2572 s / img. ETA=0:18:41\n","\u001b[32m[01/30 20:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 701/5000. 0.2576 s / img. ETA=0:18:37\n","\u001b[32m[01/30 20:59:36 d2.evaluation.evaluator]: \u001b[0mInference done 720/5000. 0.2581 s / img. ETA=0:18:35\n","\u001b[32m[01/30 20:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 739/5000. 0.2583 s / img. ETA=0:18:31\n","\u001b[32m[01/30 20:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 758/5000. 0.2586 s / img. ETA=0:18:27\n","\u001b[32m[01/30 20:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 777/5000. 0.2589 s / img. ETA=0:18:23\n","\u001b[32m[01/30 20:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 796/5000. 0.2591 s / img. ETA=0:18:19\n","\u001b[32m[01/30 21:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 815/5000. 0.2594 s / img. ETA=0:18:16\n","\u001b[32m[01/30 21:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 834/5000. 0.2595 s / img. ETA=0:18:11\n","\u001b[32m[01/30 21:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 853/5000. 0.2598 s / img. ETA=0:18:07\n","\u001b[32m[01/30 21:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 872/5000. 0.2601 s / img. ETA=0:18:04\n","\u001b[32m[01/30 21:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 891/5000. 0.2603 s / img. ETA=0:17:59\n","\u001b[32m[01/30 21:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 910/5000. 0.2603 s / img. ETA=0:17:54\n","\u001b[32m[01/30 21:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 929/5000. 0.2605 s / img. ETA=0:17:50\n","\u001b[32m[01/30 21:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 947/5000. 0.2608 s / img. ETA=0:17:47\n","\u001b[32m[01/30 21:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 966/5000. 0.2611 s / img. ETA=0:17:43\n","\u001b[32m[01/30 21:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 985/5000. 0.2612 s / img. ETA=0:17:38\n","\u001b[32m[01/30 21:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 1004/5000. 0.2615 s / img. ETA=0:17:34\n","\u001b[32m[01/30 21:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 1023/5000. 0.2615 s / img. ETA=0:17:29\n","\u001b[32m[01/30 21:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 1042/5000. 0.2617 s / img. ETA=0:17:25\n","\u001b[32m[01/30 21:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 1060/5000. 0.2620 s / img. ETA=0:17:22\n","\u001b[32m[01/30 21:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 1078/5000. 0.2623 s / img. ETA=0:17:18\n","\u001b[32m[01/30 21:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 1097/5000. 0.2625 s / img. ETA=0:17:14\n","\u001b[32m[01/30 21:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 1115/5000. 0.2627 s / img. ETA=0:17:10\n","\u001b[32m[01/30 21:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 1133/5000. 0.2630 s / img. ETA=0:17:06\n","\u001b[32m[01/30 21:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 1152/5000. 0.2632 s / img. ETA=0:17:02\n","\u001b[32m[01/30 21:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 1170/5000. 0.2634 s / img. ETA=0:16:58\n","\u001b[32m[01/30 21:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 1188/5000. 0.2637 s / img. ETA=0:16:54\n","\u001b[32m[01/30 21:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 1206/5000. 0.2639 s / img. ETA=0:16:50\n","\u001b[32m[01/30 21:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 1225/5000. 0.2640 s / img. ETA=0:16:45\n","\u001b[32m[01/30 21:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 1243/5000. 0.2642 s / img. ETA=0:16:41\n","\u001b[32m[01/30 21:02:04 d2.evaluation.evaluator]: \u001b[0mInference done 1261/5000. 0.2644 s / img. ETA=0:16:37\n","\u001b[32m[01/30 21:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 1280/5000. 0.2645 s / img. ETA=0:16:33\n","\u001b[32m[01/30 21:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 1299/5000. 0.2646 s / img. ETA=0:16:28\n","\u001b[32m[01/30 21:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 1318/5000. 0.2647 s / img. ETA=0:16:23\n","\u001b[32m[01/30 21:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 1337/5000. 0.2649 s / img. ETA=0:16:19\n","\u001b[32m[01/30 21:02:31 d2.evaluation.evaluator]: \u001b[0mInference done 1356/5000. 0.2650 s / img. ETA=0:16:14\n","\u001b[32m[01/30 21:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 1375/5000. 0.2651 s / img. ETA=0:16:10\n","\u001b[32m[01/30 21:02:41 d2.evaluation.evaluator]: \u001b[0mInference done 1394/5000. 0.2652 s / img. ETA=0:16:05\n","\u001b[32m[01/30 21:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 1413/5000. 0.2653 s / img. ETA=0:16:00\n","\u001b[32m[01/30 21:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 1432/5000. 0.2653 s / img. ETA=0:15:55\n","\u001b[32m[01/30 21:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 1450/5000. 0.2655 s / img. ETA=0:15:51\n","\u001b[32m[01/30 21:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 1469/5000. 0.2654 s / img. ETA=0:15:46\n","\u001b[32m[01/30 21:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5000. 0.2656 s / img. ETA=0:15:42\n","\u001b[32m[01/30 21:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 1505/5000. 0.2656 s / img. ETA=0:15:37\n","\u001b[32m[01/30 21:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 1524/5000. 0.2656 s / img. ETA=0:15:32\n","\u001b[32m[01/30 21:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 1542/5000. 0.2658 s / img. ETA=0:15:28\n","\u001b[32m[01/30 21:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 1560/5000. 0.2659 s / img. ETA=0:15:23\n","\u001b[32m[01/30 21:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 1578/5000. 0.2661 s / img. ETA=0:15:19\n","\u001b[32m[01/30 21:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 1596/5000. 0.2662 s / img. ETA=0:15:15\n","\u001b[32m[01/30 21:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 1614/5000. 0.2664 s / img. ETA=0:15:10\n","\u001b[32m[01/30 21:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 1633/5000. 0.2664 s / img. ETA=0:15:05\n","\u001b[32m[01/30 21:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 1652/5000. 0.2665 s / img. ETA=0:15:01\n","\u001b[32m[01/30 21:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 1670/5000. 0.2666 s / img. ETA=0:14:56\n","\u001b[32m[01/30 21:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 1689/5000. 0.2667 s / img. ETA=0:14:51\n","\u001b[32m[01/30 21:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 1707/5000. 0.2668 s / img. ETA=0:14:47\n","\u001b[32m[01/30 21:04:13 d2.evaluation.evaluator]: \u001b[0mInference done 1726/5000. 0.2669 s / img. ETA=0:14:42\n","\u001b[32m[01/30 21:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 1744/5000. 0.2670 s / img. ETA=0:14:38\n","\u001b[32m[01/30 21:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 1762/5000. 0.2672 s / img. ETA=0:14:33\n","\u001b[32m[01/30 21:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 1781/5000. 0.2671 s / img. ETA=0:14:28\n","\u001b[32m[01/30 21:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 1800/5000. 0.2672 s / img. ETA=0:14:23\n","\u001b[32m[01/30 21:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 1818/5000. 0.2673 s / img. ETA=0:14:19\n","\u001b[32m[01/30 21:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 1837/5000. 0.2674 s / img. ETA=0:14:14\n","\u001b[32m[01/30 21:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 1856/5000. 0.2674 s / img. ETA=0:14:09\n","\u001b[32m[01/30 21:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 1874/5000. 0.2676 s / img. ETA=0:14:04\n","\u001b[32m[01/30 21:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 1892/5000. 0.2676 s / img. ETA=0:14:00\n","\u001b[32m[01/30 21:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 1910/5000. 0.2677 s / img. ETA=0:13:55\n","\u001b[32m[01/30 21:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 1928/5000. 0.2678 s / img. ETA=0:13:50\n","\u001b[32m[01/30 21:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 1947/5000. 0.2679 s / img. ETA=0:13:45\n","\u001b[32m[01/30 21:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 1966/5000. 0.2679 s / img. ETA=0:13:40\n","\u001b[32m[01/30 21:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 1984/5000. 0.2680 s / img. ETA=0:13:36\n","\u001b[32m[01/30 21:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 2002/5000. 0.2681 s / img. ETA=0:13:31\n","\u001b[32m[01/30 21:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 2020/5000. 0.2682 s / img. ETA=0:13:27\n","\u001b[32m[01/30 21:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 2039/5000. 0.2682 s / img. ETA=0:13:22\n","\u001b[32m[01/30 21:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 2058/5000. 0.2682 s / img. ETA=0:13:16\n","\u001b[32m[01/30 21:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 2076/5000. 0.2683 s / img. ETA=0:13:12\n","\u001b[32m[01/30 21:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 2095/5000. 0.2683 s / img. ETA=0:13:07\n","\u001b[32m[01/30 21:06:01 d2.evaluation.evaluator]: \u001b[0mInference done 2114/5000. 0.2684 s / img. ETA=0:13:02\n","\u001b[32m[01/30 21:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 2133/5000. 0.2685 s / img. ETA=0:12:57\n","\u001b[32m[01/30 21:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 2152/5000. 0.2685 s / img. ETA=0:12:52\n","\u001b[32m[01/30 21:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 2171/5000. 0.2685 s / img. ETA=0:12:47\n","\u001b[32m[01/30 21:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 2190/5000. 0.2685 s / img. ETA=0:12:41\n","\u001b[32m[01/30 21:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 2208/5000. 0.2686 s / img. ETA=0:12:37\n","\u001b[32m[01/30 21:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 2227/5000. 0.2686 s / img. ETA=0:12:32\n","\u001b[32m[01/30 21:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 2245/5000. 0.2687 s / img. ETA=0:12:27\n","\u001b[32m[01/30 21:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 2263/5000. 0.2688 s / img. ETA=0:12:23\n","\u001b[32m[01/30 21:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 2281/5000. 0.2689 s / img. ETA=0:12:18\n","\u001b[32m[01/30 21:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 2300/5000. 0.2689 s / img. ETA=0:12:13\n","\u001b[32m[01/30 21:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 2318/5000. 0.2690 s / img. ETA=0:12:08\n","\u001b[32m[01/30 21:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 2336/5000. 0.2690 s / img. ETA=0:12:03\n","\u001b[32m[01/30 21:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 2354/5000. 0.2691 s / img. ETA=0:11:59\n","\u001b[32m[01/30 21:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 2373/5000. 0.2692 s / img. ETA=0:11:54\n","\u001b[32m[01/30 21:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 2392/5000. 0.2692 s / img. ETA=0:11:48\n","\u001b[32m[01/30 21:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 2410/5000. 0.2692 s / img. ETA=0:11:44\n","\u001b[32m[01/30 21:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 2428/5000. 0.2693 s / img. ETA=0:11:39\n","\u001b[32m[01/30 21:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 2446/5000. 0.2694 s / img. ETA=0:11:34\n","\u001b[32m[01/30 21:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 2464/5000. 0.2694 s / img. ETA=0:11:30\n","\u001b[32m[01/30 21:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 2483/5000. 0.2694 s / img. ETA=0:11:24\n","\u001b[32m[01/30 21:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 2502/5000. 0.2694 s / img. ETA=0:11:19\n","\u001b[32m[01/30 21:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 2521/5000. 0.2694 s / img. ETA=0:11:14\n","\u001b[32m[01/30 21:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 2540/5000. 0.2694 s / img. ETA=0:11:09\n","\u001b[32m[01/30 21:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 2558/5000. 0.2695 s / img. ETA=0:11:04\n","\u001b[32m[01/30 21:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 2577/5000. 0.2695 s / img. ETA=0:10:59\n","\u001b[32m[01/30 21:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 2596/5000. 0.2694 s / img. ETA=0:10:54\n","\u001b[32m[01/30 21:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 2614/5000. 0.2695 s / img. ETA=0:10:49\n","\u001b[32m[01/30 21:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 2633/5000. 0.2695 s / img. ETA=0:10:44\n","\u001b[32m[01/30 21:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 2651/5000. 0.2696 s / img. ETA=0:10:39\n","\u001b[32m[01/30 21:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 2670/5000. 0.2697 s / img. ETA=0:10:34\n","\u001b[32m[01/30 21:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 2688/5000. 0.2697 s / img. ETA=0:10:29\n","\u001b[32m[01/30 21:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 2707/5000. 0.2698 s / img. ETA=0:10:24\n","\u001b[32m[01/30 21:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 2725/5000. 0.2698 s / img. ETA=0:10:19\n","\u001b[32m[01/30 21:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 2744/5000. 0.2698 s / img. ETA=0:10:14\n","\u001b[32m[01/30 21:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 2763/5000. 0.2698 s / img. ETA=0:10:09\n","\u001b[32m[01/30 21:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 2781/5000. 0.2699 s / img. ETA=0:10:04\n","\u001b[32m[01/30 21:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 2800/5000. 0.2699 s / img. ETA=0:09:59\n","\u001b[32m[01/30 21:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 2818/5000. 0.2699 s / img. ETA=0:09:54\n","\u001b[32m[01/30 21:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 2836/5000. 0.2699 s / img. ETA=0:09:49\n","\u001b[32m[01/30 21:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 2854/5000. 0.2700 s / img. ETA=0:09:45\n","\u001b[32m[01/30 21:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 2873/5000. 0.2700 s / img. ETA=0:09:39\n","\u001b[32m[01/30 21:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 2891/5000. 0.2701 s / img. ETA=0:09:35\n","\u001b[32m[01/30 21:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 2910/5000. 0.2702 s / img. ETA=0:09:30\n","\u001b[32m[01/30 21:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 2929/5000. 0.2702 s / img. ETA=0:09:24\n","\u001b[32m[01/30 21:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 2948/5000. 0.2702 s / img. ETA=0:09:19\n","\u001b[32m[01/30 21:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 2966/5000. 0.2702 s / img. ETA=0:09:15\n","\u001b[32m[01/30 21:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 2984/5000. 0.2703 s / img. ETA=0:09:10\n","\u001b[32m[01/30 21:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 3003/5000. 0.2703 s / img. ETA=0:09:05\n","\u001b[32m[01/30 21:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 3021/5000. 0.2704 s / img. ETA=0:09:00\n","\u001b[32m[01/30 21:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 3039/5000. 0.2704 s / img. ETA=0:08:55\n","\u001b[32m[01/30 21:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 3057/5000. 0.2705 s / img. ETA=0:08:50\n","\u001b[32m[01/30 21:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 3075/5000. 0.2705 s / img. ETA=0:08:45\n","\u001b[32m[01/30 21:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 3093/5000. 0.2706 s / img. ETA=0:08:41\n","\u001b[32m[01/30 21:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 3112/5000. 0.2706 s / img. ETA=0:08:35\n","\u001b[32m[01/30 21:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 3130/5000. 0.2707 s / img. ETA=0:08:31\n","\u001b[32m[01/30 21:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 3148/5000. 0.2707 s / img. ETA=0:08:26\n","\u001b[32m[01/30 21:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 3167/5000. 0.2707 s / img. ETA=0:08:21\n","\u001b[32m[01/30 21:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 3185/5000. 0.2707 s / img. ETA=0:08:16\n","\u001b[32m[01/30 21:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 3203/5000. 0.2708 s / img. ETA=0:08:11\n","\u001b[32m[01/30 21:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 3222/5000. 0.2708 s / img. ETA=0:08:06\n","\u001b[32m[01/30 21:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 3240/5000. 0.2708 s / img. ETA=0:08:01\n","\u001b[32m[01/30 21:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 3259/5000. 0.2708 s / img. ETA=0:07:56\n","\u001b[32m[01/30 21:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 3277/5000. 0.2709 s / img. ETA=0:07:51\n","\u001b[32m[01/30 21:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 3295/5000. 0.2709 s / img. ETA=0:07:46\n","\u001b[32m[01/30 21:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 3313/5000. 0.2710 s / img. ETA=0:07:41\n","\u001b[32m[01/30 21:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 3331/5000. 0.2710 s / img. ETA=0:07:36\n","\u001b[32m[01/30 21:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 3350/5000. 0.2710 s / img. ETA=0:07:31\n","\u001b[32m[01/30 21:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 3368/5000. 0.2710 s / img. ETA=0:07:26\n","\u001b[32m[01/30 21:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 3386/5000. 0.2710 s / img. ETA=0:07:21\n","\u001b[32m[01/30 21:12:00 d2.evaluation.evaluator]: \u001b[0mInference done 3405/5000. 0.2710 s / img. ETA=0:07:16\n","\u001b[32m[01/30 21:12:05 d2.evaluation.evaluator]: \u001b[0mInference done 3423/5000. 0.2711 s / img. ETA=0:07:11\n","\u001b[32m[01/30 21:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 3441/5000. 0.2711 s / img. ETA=0:07:06\n","\u001b[32m[01/30 21:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 3459/5000. 0.2711 s / img. ETA=0:07:01\n","\u001b[32m[01/30 21:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 3477/5000. 0.2712 s / img. ETA=0:06:56\n","\u001b[32m[01/30 21:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 3496/5000. 0.2712 s / img. ETA=0:06:51\n","\u001b[32m[01/30 21:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 3515/5000. 0.2712 s / img. ETA=0:06:46\n","\u001b[32m[01/30 21:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 3533/5000. 0.2712 s / img. ETA=0:06:41\n","\u001b[32m[01/30 21:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 3552/5000. 0.2712 s / img. ETA=0:06:36\n","\u001b[32m[01/30 21:12:46 d2.evaluation.evaluator]: \u001b[0mInference done 3570/5000. 0.2712 s / img. ETA=0:06:31\n","\u001b[32m[01/30 21:12:51 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5000. 0.2712 s / img. ETA=0:06:26\n","\u001b[32m[01/30 21:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 3608/5000. 0.2712 s / img. ETA=0:06:21\n","\u001b[32m[01/30 21:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 3626/5000. 0.2713 s / img. ETA=0:06:16\n","\u001b[32m[01/30 21:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 3644/5000. 0.2713 s / img. ETA=0:06:11\n","\u001b[32m[01/30 21:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 3662/5000. 0.2713 s / img. ETA=0:06:06\n","\u001b[32m[01/30 21:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 3680/5000. 0.2714 s / img. ETA=0:06:01\n","\u001b[32m[01/30 21:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 3699/5000. 0.2714 s / img. ETA=0:05:56\n","\u001b[32m[01/30 21:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 3718/5000. 0.2714 s / img. ETA=0:05:51\n","\u001b[32m[01/30 21:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 3736/5000. 0.2714 s / img. ETA=0:05:46\n","\u001b[32m[01/30 21:13:37 d2.evaluation.evaluator]: \u001b[0mInference done 3755/5000. 0.2714 s / img. ETA=0:05:41\n","\u001b[32m[01/30 21:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 3774/5000. 0.2714 s / img. ETA=0:05:35\n","\u001b[32m[01/30 21:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 3792/5000. 0.2715 s / img. ETA=0:05:31\n","\u001b[32m[01/30 21:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 3811/5000. 0.2715 s / img. ETA=0:05:25\n","\u001b[32m[01/30 21:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 3829/5000. 0.2715 s / img. ETA=0:05:21\n","\u001b[32m[01/30 21:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 3847/5000. 0.2716 s / img. ETA=0:05:16\n","\u001b[32m[01/30 21:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 3865/5000. 0.2716 s / img. ETA=0:05:11\n","\u001b[32m[01/30 21:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 3884/5000. 0.2716 s / img. ETA=0:05:06\n","\u001b[32m[01/30 21:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 3903/5000. 0.2716 s / img. ETA=0:05:00\n","\u001b[32m[01/30 21:14:23 d2.evaluation.evaluator]: \u001b[0mInference done 3922/5000. 0.2716 s / img. ETA=0:04:55\n","\u001b[32m[01/30 21:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 3941/5000. 0.2716 s / img. ETA=0:04:50\n","\u001b[32m[01/30 21:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 3959/5000. 0.2716 s / img. ETA=0:04:45\n","\u001b[32m[01/30 21:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 3978/5000. 0.2716 s / img. ETA=0:04:40\n","\u001b[32m[01/30 21:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 3997/5000. 0.2716 s / img. ETA=0:04:35\n","\u001b[32m[01/30 21:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 4016/5000. 0.2716 s / img. ETA=0:04:29\n","\u001b[32m[01/30 21:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 4035/5000. 0.2716 s / img. ETA=0:04:24\n","\u001b[32m[01/30 21:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 4053/5000. 0.2716 s / img. ETA=0:04:19\n","\u001b[32m[01/30 21:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 4072/5000. 0.2716 s / img. ETA=0:04:14\n","\u001b[32m[01/30 21:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 4091/5000. 0.2716 s / img. ETA=0:04:09\n","\u001b[32m[01/30 21:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 4109/5000. 0.2717 s / img. ETA=0:04:04\n","\u001b[32m[01/30 21:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 4127/5000. 0.2717 s / img. ETA=0:03:59\n","\u001b[32m[01/30 21:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 4146/5000. 0.2717 s / img. ETA=0:03:54\n","\u001b[32m[01/30 21:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 4165/5000. 0.2717 s / img. ETA=0:03:49\n","\u001b[32m[01/30 21:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 4184/5000. 0.2717 s / img. ETA=0:03:43\n","\u001b[32m[01/30 21:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 4202/5000. 0.2718 s / img. ETA=0:03:38\n","\u001b[32m[01/30 21:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 4221/5000. 0.2718 s / img. ETA=0:03:33\n","\u001b[32m[01/30 21:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 4241/5000. 0.2717 s / img. ETA=0:03:28\n","\u001b[32m[01/30 21:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 4259/5000. 0.2717 s / img. ETA=0:03:23\n","\u001b[32m[01/30 21:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 4278/5000. 0.2718 s / img. ETA=0:03:18\n","\u001b[32m[01/30 21:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 4297/5000. 0.2718 s / img. ETA=0:03:12\n","\u001b[32m[01/30 21:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 4315/5000. 0.2718 s / img. ETA=0:03:07\n","\u001b[32m[01/30 21:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 4334/5000. 0.2718 s / img. ETA=0:03:02\n","\u001b[32m[01/30 21:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 4353/5000. 0.2718 s / img. ETA=0:02:57\n","\u001b[32m[01/30 21:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 4371/5000. 0.2718 s / img. ETA=0:02:52\n","\u001b[32m[01/30 21:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 4390/5000. 0.2718 s / img. ETA=0:02:47\n","\u001b[32m[01/30 21:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 4409/5000. 0.2718 s / img. ETA=0:02:42\n","\u001b[32m[01/30 21:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 4428/5000. 0.2718 s / img. ETA=0:02:36\n","\u001b[32m[01/30 21:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 4446/5000. 0.2718 s / img. ETA=0:02:32\n","\u001b[32m[01/30 21:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 4464/5000. 0.2719 s / img. ETA=0:02:27\n","\u001b[32m[01/30 21:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 4483/5000. 0.2719 s / img. ETA=0:02:21\n","\u001b[32m[01/30 21:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 4501/5000. 0.2719 s / img. ETA=0:02:16\n","\u001b[32m[01/30 21:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 4519/5000. 0.2719 s / img. ETA=0:02:12\n","\u001b[32m[01/30 21:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 4538/5000. 0.2719 s / img. ETA=0:02:06\n","\u001b[32m[01/30 21:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 4557/5000. 0.2719 s / img. ETA=0:02:01\n","\u001b[32m[01/30 21:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 4576/5000. 0.2719 s / img. ETA=0:01:56\n","\u001b[32m[01/30 21:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 4594/5000. 0.2719 s / img. ETA=0:01:51\n","\u001b[32m[01/30 21:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 4612/5000. 0.2720 s / img. ETA=0:01:46\n","\u001b[32m[01/30 21:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 4631/5000. 0.2720 s / img. ETA=0:01:41\n","\u001b[32m[01/30 21:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 4649/5000. 0.2720 s / img. ETA=0:01:36\n","\u001b[32m[01/30 21:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 4668/5000. 0.2720 s / img. ETA=0:01:31\n","\u001b[32m[01/30 21:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 4687/5000. 0.2720 s / img. ETA=0:01:25\n","\u001b[32m[01/30 21:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 4705/5000. 0.2720 s / img. ETA=0:01:21\n","\u001b[32m[01/30 21:18:05 d2.evaluation.evaluator]: \u001b[0mInference done 4724/5000. 0.2720 s / img. ETA=0:01:15\n","\u001b[32m[01/30 21:18:10 d2.evaluation.evaluator]: \u001b[0mInference done 4742/5000. 0.2721 s / img. ETA=0:01:10\n","\u001b[32m[01/30 21:18:15 d2.evaluation.evaluator]: \u001b[0mInference done 4760/5000. 0.2721 s / img. ETA=0:01:05\n","\u001b[32m[01/30 21:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 4779/5000. 0.2721 s / img. ETA=0:01:00\n","\u001b[32m[01/30 21:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 4797/5000. 0.2721 s / img. ETA=0:00:55\n","\u001b[32m[01/30 21:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 4816/5000. 0.2721 s / img. ETA=0:00:50\n","\u001b[32m[01/30 21:18:36 d2.evaluation.evaluator]: \u001b[0mInference done 4836/5000. 0.2721 s / img. ETA=0:00:45\n","\u001b[32m[01/30 21:18:41 d2.evaluation.evaluator]: \u001b[0mInference done 4854/5000. 0.2721 s / img. ETA=0:00:40\n","\u001b[32m[01/30 21:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 4872/5000. 0.2721 s / img. ETA=0:00:35\n","\u001b[32m[01/30 21:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 4890/5000. 0.2722 s / img. ETA=0:00:30\n","\u001b[32m[01/30 21:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 4909/5000. 0.2722 s / img. ETA=0:00:25\n","\u001b[32m[01/30 21:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 4927/5000. 0.2722 s / img. ETA=0:00:20\n","\u001b[32m[01/30 21:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 4945/5000. 0.2722 s / img. ETA=0:00:15\n","\u001b[32m[01/30 21:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 4963/5000. 0.2723 s / img. ETA=0:00:10\n","\u001b[32m[01/30 21:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 4982/5000. 0.2723 s / img. ETA=0:00:04\n","\u001b[32m[01/30 21:19:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:22:53.286938 (0.274932 s / img per device, on 1 devices)\n","\u001b[32m[01/30 21:19:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:22:40 (0.272282 s / img per device, on 1 devices)\n","\u001b[32m[01/30 21:19:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[01/30 21:19:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n","\u001b[32m[01/30 21:19:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n","Loading and preparing results...\n","DONE (t=0.45s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=29.15s).\n","Accumulating evaluation results...\n","DONE (t=3.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.469\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n","\u001b[32m[01/30 21:19:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 43.047 | 63.652 | 46.888 | 27.205 | 46.093 | 54.890 |\n","\u001b[32m[01/30 21:19:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category      | AP     | category     | AP     | category       | AP     |\n","|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n","| person        | 56.584 | bicycle      | 33.478 | car            | 46.274 |\n","| motorcycle    | 44.864 | airplane     | 65.970 | bus            | 67.801 |\n","| train         | 63.855 | truck        | 37.523 | boat           | 29.088 |\n","| traffic light | 28.431 | fire hydrant | 67.848 | stop sign      | 67.426 |\n","| parking meter | 47.115 | bench        | 26.732 | bird           | 40.608 |\n","| cat           | 68.564 | dog          | 63.084 | horse          | 60.519 |\n","| sheep         | 52.939 | cow          | 57.419 | elephant       | 62.942 |\n","| bear          | 71.289 | zebra        | 66.869 | giraffe        | 66.830 |\n","| backpack      | 18.215 | umbrella     | 40.402 | handbag        | 16.905 |\n","| tie           | 36.589 | suitcase     | 43.065 | frisbee        | 67.470 |\n","| skis          | 26.227 | snowboard    | 38.807 | sports ball    | 48.196 |\n","| kite          | 42.842 | baseball bat | 31.106 | baseball glove | 40.043 |\n","| skateboard    | 56.111 | surfboard    | 40.490 | tennis racket  | 51.013 |\n","| bottle        | 40.653 | wine glass   | 38.639 | cup            | 44.779 |\n","| fork          | 40.702 | knife        | 22.446 | spoon          | 21.464 |\n","| bowl          | 42.973 | banana       | 23.170 | apple          | 24.199 |\n","| sandwich      | 33.904 | orange       | 31.624 | broccoli       | 22.489 |\n","| carrot        | 21.827 | hot dog      | 34.902 | pizza          | 52.478 |\n","| donut         | 45.543 | cake         | 36.834 | chair          | 29.421 |\n","| couch         | 43.671 | potted plant | 28.094 | bed            | 41.796 |\n","| dining table  | 28.766 | toilet       | 60.039 | tv             | 58.110 |\n","| laptop        | 61.864 | mouse        | 62.764 | remote         | 34.984 |\n","| keyboard      | 52.624 | cell phone   | 38.827 | microwave      | 61.060 |\n","| oven          | 33.099 | toaster      | 36.892 | sink           | 37.416 |\n","| refrigerator  | 55.290 | book         | 15.653 | clock          | 50.330 |\n","| vase          | 37.752 | scissors     | 27.406 | teddy bear     | 46.587 |\n","| hair drier    | 5.592  | toothbrush   | 25.559 |                |        |\n","\u001b[32m[01/30 21:19:58 d2.engine.defaults]: \u001b[0mEvaluation results for coco_2017_val in csv format:\n","\u001b[32m[01/30 21:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[01/30 21:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[01/30 21:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: 43.0470,63.6518,46.8884,27.2050,46.0934,54.8902\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iJqwT8JROyq0"},"source":["Sauvegarde des résultats sur Google Drive :"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uF-LuI_rOyq3","colab":{}},"source":["!cp detectron2_repo/output/log.txt /content/drive/My\\ Drive/res_eval_redev/faster_rcnn_x101_fpn.txt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qPU85TpYVld8","colab_type":"text"},"source":["## RetinaNet"]},{"cell_type":"code","metadata":{"id":"HZ1bQ78eVxLr","colab_type":"code","outputId":"256ff6b6-0d46-4656-d44f-fe9467a84492","executionInfo":{"status":"ok","timestamp":1580420765657,"user_tz":-60,"elapsed":1198179,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-Detection/retinanet_R_101_FPN_3x/138363263/model_final_59f53c.pkl > output/retinanet_r101.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading config configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n","model_final_59f53c.pkl: 228MB [00:14, 16.0MB/s]               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gRGpIKSGWM7Y","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/retinanet_r101.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCtEMmWabdCC","colab_type":"text"},"source":["## Mask R-CNN"]},{"cell_type":"markdown","metadata":{"id":"kaw5RNq9bgsQ","colab_type":"text"},"source":["### R50-FPN"]},{"cell_type":"code","metadata":{"id":"deseSnEabgH4","colab_type":"code","outputId":"86b2c394-00c7-4b7f-ca26-e78ba5192195","executionInfo":{"status":"ok","timestamp":1580422130500,"user_tz":-60,"elapsed":889745,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl > output/mask_rcnn_r50_fpn.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["model_final_f10217.pkl: 178MB [00:10, 16.5MB/s]               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fkOq6p_EbrYQ","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/mask_rcnn_r50_fpn.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dTxRIlIcbkwl","colab_type":"text"},"source":["### X101-FPN"]},{"cell_type":"code","metadata":{"id":"yS77teUUbnQX","colab_type":"code","outputId":"1cd2f251-1cc5-4baf-db3b-e3c31612eec7","executionInfo":{"status":"ok","timestamp":1580424471222,"user_tz":-60,"elapsed":1624278,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl > output/mask_rcnn_x101_fpn.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["model_final_2d9806.pkl: 431MB [00:20, 21.1MB/s]               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OmZWKNkWbr-R","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/mask_rcnn_x101_fpn.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ukl0V8eXdRFW","colab_type":"text"},"source":["## Cascade Mask R-CNN"]},{"cell_type":"code","metadata":{"id":"gWe7rDAQdTYE","colab_type":"code","colab":{}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://Misc/cascade_mask_rcnn_R_50_FPN_3x/144998488/model_final_480dd8.pkl > output/cascade_mask_rcnn.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxWEVUNldV4G","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/cascade_mask_rcnn.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZEK81vQSMDz","colab_type":"text"},"source":["## Panoptic FPN"]},{"cell_type":"code","metadata":{"id":"7ykFKFMUUaF4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"outputId":"49209fa6-0cf9-463f-80aa-2fee06a068f9","executionInfo":{"status":"ok","timestamp":1580855326297,"user_tz":-60,"elapsed":8967,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}}},"source":["!pip install git+https://github.com/cocodataset/panopticapi.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/cocodataset/panopticapi.git\n","  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-0zfzf_oi\n","  Running command git clone -q https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-0zfzf_oi\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from panopticapi==0.1) (1.17.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from panopticapi==0.1) (6.2.2)\n","Building wheels for collected packages: panopticapi\n","  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for panopticapi: filename=panopticapi-0.1-cp36-none-any.whl size=8317 sha256=46bf05173c1c8c311bf4d6684286d234512986a9f8232c07b077a1b4661e66f0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ds6czuy6/wheels/41/ae/17/f7e628e1ba4776ceea035aefb113ef24b6639ad5d5a2e5a5d1\n","Successfully built panopticapi\n","Installing collected packages: panopticapi\n","Successfully installed panopticapi-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1P8F5F4lUf_l","colab_type":"code","colab":{}},"source":["%%bash\n","cd detectron2_repo/datasets\n","mkdir coco\n","cd coco\n","cp /content/drive/My\\ Drive/data_redev/coco/panoptic_annotations_trainval2017.zip .\n","unzip panoptic_annotations_trainval2017.zip\n","unzip annotations/panoptic_val2017.zip\n","cp /content/drive/My\\ Drive/data_redev/coco/annotations/instances_val2017.json annotations/\n","cp /content/drive/My\\ Drive/data_redev/coco/val2017.zip .\n","unzip val2017.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGCvm0vYWWGm","colab_type":"code","colab":{}},"source":["!cd detectron2_repo/datasets && python prepare_panoptic_fpn.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ju5FNyJRTwu","colab_type":"text"},"source":["### Panoptic R50-FPN"]},{"cell_type":"code","metadata":{"id":"UEuN7HJDroXK","colab_type":"code","colab":{}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_50_3x/139514569/model_final_c10459.pkl > output/panoptic_r50_fpn.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHrSNBpeRevB","colab_type":"code","colab":{}},"source":["!cp detectron2_repo/output/panoptic_r50_fpn.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RBXnLB2oSRlL"},"source":["### Panoptic R101-FPN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UU12Mn7wSRlR","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7757b3a8-70a9-4442-8417-3b2c4c3f386d","executionInfo":{"status":"ok","timestamp":1580859283959,"user_tz":-60,"elapsed":2602637,"user":{"displayName":"Benjamin Beaucamp","photoUrl":"","userId":"13955152155811907680"}}},"source":["!cd detectron2_repo && python tools/train_net.py \\\n","\t--config-file configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml \\\n","\t--eval-only MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_101_3x/139514519/model_final_cafdb1.pkl > output/panoptic_r101_fpn.txt"],"execution_count":18,"outputs":[{"output_type":"stream","text":["model_final_cafdb1.pkl: 261MB [00:27, 9.34MB/s]               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jri4rXxeSRlc","colab":{}},"source":["!cp detectron2_repo/output/panoptic_r101_fpn.txt /content/drive/My\\ Drive/res_eval_redev"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_CN6I_CZqSm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}